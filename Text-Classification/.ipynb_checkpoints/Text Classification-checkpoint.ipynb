{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Learning Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Background information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Traditional Machine Learning can be processed by the the standard process for data mining \"CRISP-DM\". However, the processing of NLP's Text Classification task is slightly different from the conventional machine learning process. We need to make some subtle adjustments to the process based on the Crisp-DM model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"CRISP-DM_Process.jpg\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Text Classification Process(Based on CRISP-DM process)\n",
    "The following is a summary of some of the processing procedures for dealing with Text Classification problems that I have obtained by looking through different projects, materials and papers from the internet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Business Understanding\n",
    "* #### Data Exploratory\n",
    "* #### Data Preparation\n",
    "    * #### Feature Engineering\n",
    "        * #### Text representation\n",
    "        * #### Text cleaning\n",
    "        * #### Label coding\n",
    "        * #### Train — test split\n",
    "* #### Modeling\n",
    "    * #### Hyperparameter tuning methodology and models\n",
    "* #### Evaluation\n",
    "    * #### Performance Measurement\n",
    "    * #### Best Model Selection\n",
    "    * #### Model Interpretation\n",
    "* #### Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploratory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data balance\n",
    "One of our main concerns is whether the different classes are balanced. This means that the dataset contains an approximately equal portion of each class.There are several ways of dealing with imbalanced datasets. \n",
    "\n",
    "### 3.2 Checking the quality of text\n",
    "Checking for any messy code or website tag or post that needs to be clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Text Representation\n",
    "\n",
    "in order to represent our text, every row of the dataset will be a single document of the corpus. The columns (features) will be different depending of which feature creation method we choose:\n",
    "\n",
    "* Word Count Vectors\n",
    "* TF–IDF Vectors\n",
    "* Word2vector\n",
    "* CBOW\n",
    "* GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Text Cleaning\n",
    "\n",
    "Before creating any feature from the raw text, we must perform a cleaning process to ensure no distortions are introduced to the model. We have followed these steps:\n",
    "\n",
    "* Special character cleaning\n",
    "* Upcase/downcase\n",
    "* Punctuation signs\n",
    "* Possessive pronouns\n",
    "* Stemming or Lemmatization\n",
    "* Stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 Label coding\n",
    "\n",
    "Machine learning models require numeric features and labels to provide a prediction. For this reason we must create a dictionary to map each label to a numerical ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.4 Train — test split\n",
    "\n",
    "Spiliting data set into tran dataset and test dataset, there are some methods we choose:\n",
    "* 70% for training dataset and 30% for testing dataset\n",
    "* k-folds cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tried the following models:\n",
    "\n",
    "* Conventional Machine Learning Algorithm\n",
    "    * Random Forest\n",
    "    * SVM\n",
    "    * KNN\n",
    "    * NB(Naive Bayes)\n",
    "    * Logistic Regression\n",
    "    * Gradient Boosting\n",
    "* Deep learning Algorithm\n",
    "    * BERT\n",
    "    * LSTM\n",
    "    * CNN\n",
    "    * RNN\n",
    "    * ANN\n",
    "    * HAN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Performance Measurement\n",
    "\n",
    "When dealing with classification problems, there are several metrics that can be used to gain insights on how the model is performing. Some of them are:\n",
    " \n",
    " * Accuracy\n",
    " * confusion matrix\n",
    " * Precision\n",
    " * Recall\n",
    " * F1-Score\n",
    " * ROC\n",
    " * classification report(for the SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Best Model Selection\n",
    "Based on the model performance choose the highest accuracy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Model Interpretation\n",
    "\n",
    "studying its behavior by analyzing misclassified articles, in order to get some insights on the way the model is working and avoid misclassified"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
