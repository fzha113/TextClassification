{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Learning Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Background information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Traditional Machine Learning can be processed by the the standard process for data mining \"CRISP-DM\". However, the processing of NLP's Text Classification task is slightly different from the conventional machine learning process. We need to make some subtle adjustments to the process based on the Crisp-DM model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"CRISP-DM_Process.jpg\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Text Classification Process(Based on CRISP-DM process)\n",
    "The following is a summary of some of the processing procedures for dealing with Text Classification problems that I have obtained by looking through different projects, materials and papers from the internet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Business Understanding\n",
    "* Data Exploratory\n",
    "* Data Preparation\n",
    "    * Feature Engineering\n",
    "        * Text cleaning\n",
    "        * Text representation\n",
    "        * Label coding\n",
    "        * Train — test split\n",
    "* Modeling\n",
    "    * Hyperparameter tuning methodology and models\n",
    "* Evaluation\n",
    "    * Performance Measurement\n",
    "    * Best Model Selection\n",
    "    * Model Interpretation\n",
    "* Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Business Understanding\n",
    "\n",
    "\n",
    "## Business Understanding\n",
    "\n",
    "### The task is a binary label's text classification. By training the original text and labels to predict new text's label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Exploratory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__2 Stuning even for the non-gamer: Thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__2 The best soundtrack ever to anythin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__2 Amazing!: This soundtrack is my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__2 Excellent Soundtrack: I truly like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__2 Remember, Pull Your Jaw Off The Flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>__label__2 an absolute masterpiece: I am quite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>__label__1 Buyer beware: This is a self-publis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>__label__2 Glorious story: I loved Whisper of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>__label__2 A FIVE STAR BOOK: I just finished r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>__label__2 Whispers of the Wicked Saints: This...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 raw\n",
       "0  __label__2 Stuning even for the non-gamer: Thi...\n",
       "1  __label__2 The best soundtrack ever to anythin...\n",
       "2  __label__2 Amazing!: This soundtrack is my fav...\n",
       "3  __label__2 Excellent Soundtrack: I truly like ...\n",
       "4  __label__2 Remember, Pull Your Jaw Off The Flo...\n",
       "5  __label__2 an absolute masterpiece: I am quite...\n",
       "6  __label__1 Buyer beware: This is a self-publis...\n",
       "7  __label__2 Glorious story: I loved Whisper of ...\n",
       "8  __label__2 A FIVE STAR BOOK: I just finished r...\n",
       "9  __label__2 Whispers of the Wicked Saints: This..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('./dataset_of_text_classification.txt',header=None)\n",
    "df.columns = ['raw']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting response feature as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__2 Stuning even for the non-gamer: Thi...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__2 The best soundtrack ever to anythin...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__2 Amazing!: This soundtrack is my fav...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite musi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__2 Excellent Soundtrack: I truly like ...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>Excellent Soundtrack: I truly like this sound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__2 Remember, Pull Your Jaw Off The Flo...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>__label__2 an absolute masterpiece: I am quite...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>an absolute masterpiece: I am quite sure any ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>__label__1 Buyer beware: This is a self-publis...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>Buyer beware: This is a self-published book, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>__label__2 Glorious story: I loved Whisper of ...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>Glorious story: I loved Whisper of the wicked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>__label__2 A FIVE STAR BOOK: I just finished r...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>A FIVE STAR BOOK: I just finished reading Whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>__label__2 Whispers of the Wicked Saints: This...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>Whispers of the Wicked Saints: This was a eas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>__label__1 The Worst!: A complete waste of tim...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>The Worst!: A complete waste of time. Typogra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>__label__2 Great book: This was a great book,I...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>Great book: This was a great book,I just coul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>__label__2 Great Read: I thought this book was...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>Great Read: I thought this book was brilliant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>__label__1 Oh please: I guess you have to be a...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>Oh please: I guess you have to be a romance n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>__label__1 Awful beyond belief!: I feel I have...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>Awful beyond belief!: I feel I have to write ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>__label__1 Don't try to fool us with fake revi...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>Don't try to fool us with fake reviews.: It's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>__label__2 A romantic zen baseball comedy: Whe...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>A romantic zen baseball comedy: When you hear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>__label__2 Fashionable Compression Stockings!:...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>Fashionable Compression Stockings!: After I h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>__label__2 Jobst UltraSheer Thigh High: Excell...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>Jobst UltraSheer Thigh High: Excellent produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>__label__1 sizes recomended in the size chart ...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>sizes recomended in the size chart are not re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  raw       label  \\\n",
       "0   __label__2 Stuning even for the non-gamer: Thi...  __label__2   \n",
       "1   __label__2 The best soundtrack ever to anythin...  __label__2   \n",
       "2   __label__2 Amazing!: This soundtrack is my fav...  __label__2   \n",
       "3   __label__2 Excellent Soundtrack: I truly like ...  __label__2   \n",
       "4   __label__2 Remember, Pull Your Jaw Off The Flo...  __label__2   \n",
       "5   __label__2 an absolute masterpiece: I am quite...  __label__2   \n",
       "6   __label__1 Buyer beware: This is a self-publis...  __label__1   \n",
       "7   __label__2 Glorious story: I loved Whisper of ...  __label__2   \n",
       "8   __label__2 A FIVE STAR BOOK: I just finished r...  __label__2   \n",
       "9   __label__2 Whispers of the Wicked Saints: This...  __label__2   \n",
       "10  __label__1 The Worst!: A complete waste of tim...  __label__1   \n",
       "11  __label__2 Great book: This was a great book,I...  __label__2   \n",
       "12  __label__2 Great Read: I thought this book was...  __label__2   \n",
       "13  __label__1 Oh please: I guess you have to be a...  __label__1   \n",
       "14  __label__1 Awful beyond belief!: I feel I have...  __label__1   \n",
       "15  __label__1 Don't try to fool us with fake revi...  __label__1   \n",
       "16  __label__2 A romantic zen baseball comedy: Whe...  __label__2   \n",
       "17  __label__2 Fashionable Compression Stockings!:...  __label__2   \n",
       "18  __label__2 Jobst UltraSheer Thigh High: Excell...  __label__2   \n",
       "19  __label__1 sizes recomended in the size chart ...  __label__1   \n",
       "\n",
       "                                                 text  \n",
       "0    Stuning even for the non-gamer: This sound tr...  \n",
       "1    The best soundtrack ever to anything.: I'm re...  \n",
       "2    Amazing!: This soundtrack is my favorite musi...  \n",
       "3    Excellent Soundtrack: I truly like this sound...  \n",
       "4    Remember, Pull Your Jaw Off The Floor After H...  \n",
       "5    an absolute masterpiece: I am quite sure any ...  \n",
       "6    Buyer beware: This is a self-published book, ...  \n",
       "7    Glorious story: I loved Whisper of the wicked...  \n",
       "8    A FIVE STAR BOOK: I just finished reading Whi...  \n",
       "9    Whispers of the Wicked Saints: This was a eas...  \n",
       "10   The Worst!: A complete waste of time. Typogra...  \n",
       "11   Great book: This was a great book,I just coul...  \n",
       "12   Great Read: I thought this book was brilliant...  \n",
       "13   Oh please: I guess you have to be a romance n...  \n",
       "14   Awful beyond belief!: I feel I have to write ...  \n",
       "15   Don't try to fool us with fake reviews.: It's...  \n",
       "16   A romantic zen baseball comedy: When you hear...  \n",
       "17   Fashionable Compression Stockings!: After I h...  \n",
       "18   Jobst UltraSheer Thigh High: Excellent produc...  \n",
       "19   sizes recomended in the size chart are not re...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting label column into a new column\n",
    "df['label'] = df['raw'].str.extract('(__label__.)', expand=True)\n",
    "\n",
    "# Remove the label from the raw text, and The rest of the text is extracted into a new column\n",
    "df['text'] = df['raw'].str.replace('(__label__.)','')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data balance\n",
    "One of our main concerns is whether the different classes are balanced. This means that the dataset contains an approximately equal portion of each class.There are several ways of dealing with imbalanced datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "805532"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is only 800k words. It is quite small but makes sure we don't have to wait a long time for the code to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'count'),\n",
       " Text(0.5, 0, 'label'),\n",
       " Text(0.5, 1.0, 'number of labels in each category')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "sns.barplot(x= df.label.unique(),y= df.label.value_counts())\n",
    "ax.set(xlabel='label', ylabel='count',title=\"number of labels in each category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are very well balanced!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Checking the quality of text\n",
    "Checking for any messy code or website tag or post that needs to be clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: __label__2\n",
      "text:  Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\n",
      "\t\n",
      "label: __label__1\n",
      "text:  mens ultrasheer: This model may be ok for sedentary types, but I'm active and get around alot in my job - consistently found these stockings rolled up down by my ankles! Not Good!! Solution: go with the standard compression stocking, 20-30, stock #114622. Excellent support, stays up and gives me what I need. Both pair of these also tore as I struggled to pull them up all the time. Good riddance/bad investment!\n",
      "\t\n",
      "label: __label__2\n",
      "text:  textbook: Book shipped quickly and was in excellent condition as stated. Easy transaction would buy again\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "def print_plot(index, text_column):\n",
    "    example = df[df.index == index][['label', text_column]].values[0]\n",
    "    if len(example) > 0:\n",
    "        print('label:', example[0])\n",
    "        print('text:', example[1])\n",
    "        print('\\t')\n",
    "        \n",
    "print_plot(0, 'text')\n",
    "print_plot(20, 'text')\n",
    "print_plot(100, 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are some emotion icons in the text need to be cleaned up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Text Cleaning\n",
    "\n",
    "Before creating any feature from the raw text, we must perform a cleaning process to ensure no distortions are introduced to the model. We have followed these steps:\n",
    "\n",
    "* Special character cleaning\n",
    "* Upcase/downcase\n",
    "* Punctuation signs\n",
    "* Possessive pronouns\n",
    "* Stemming or Lemmatization\n",
    "* Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: one\n",
      "text: one\n",
      "\t\n",
      "label: one\n",
      "text: mens ultrasheer model may ok sedentary types im active get around alot job consistently found stockings rolled ankles good solution go standard compression stocking 2030 stock 114622 excellent support stays gives need pair also tore struggled pull time good riddance bad investment\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[#_/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "df['label'].loc[df['label'] == '__label__1'] = 'one'\n",
    "df['label'].loc[df['label'] == '__label__2'] = 'two'\n",
    "\n",
    "print_plot(20, 'label')\n",
    "print_plot(20, 'clean_text')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__2 Stuning even for the non-gamer: Thi...</td>\n",
       "      <td>two</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tr...</td>\n",
       "      <td>stuning even nongamer sound track beautiful pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__2 The best soundtrack ever to anythin...</td>\n",
       "      <td>two</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm re...</td>\n",
       "      <td>best soundtrack ever anything im reading lot r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__2 Amazing!: This soundtrack is my fav...</td>\n",
       "      <td>two</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite musi...</td>\n",
       "      <td>amazing soundtrack favorite music time hands i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__2 Excellent Soundtrack: I truly like ...</td>\n",
       "      <td>two</td>\n",
       "      <td>Excellent Soundtrack: I truly like this sound...</td>\n",
       "      <td>excellent soundtrack truly like soundtrack enj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__2 Remember, Pull Your Jaw Off The Flo...</td>\n",
       "      <td>two</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After H...</td>\n",
       "      <td>remember pull jaw floor hearing youve played g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>__label__2 an absolute masterpiece: I am quite...</td>\n",
       "      <td>two</td>\n",
       "      <td>an absolute masterpiece: I am quite sure any ...</td>\n",
       "      <td>absolute masterpiece quite sure actually takin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>__label__1 Buyer beware: This is a self-publis...</td>\n",
       "      <td>one</td>\n",
       "      <td>Buyer beware: This is a self-published book, ...</td>\n",
       "      <td>buyer beware selfpublished book want know whyr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>__label__2 Glorious story: I loved Whisper of ...</td>\n",
       "      <td>two</td>\n",
       "      <td>Glorious story: I loved Whisper of the wicked...</td>\n",
       "      <td>glorious story loved whisper wicked saints sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>__label__2 A FIVE STAR BOOK: I just finished r...</td>\n",
       "      <td>two</td>\n",
       "      <td>A FIVE STAR BOOK: I just finished reading Whi...</td>\n",
       "      <td>five star book finished reading whisper wicked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>__label__2 Whispers of the Wicked Saints: This...</td>\n",
       "      <td>two</td>\n",
       "      <td>Whispers of the Wicked Saints: This was a eas...</td>\n",
       "      <td>whispers wicked saints easy read book made wan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 raw label  \\\n",
       "0  __label__2 Stuning even for the non-gamer: Thi...   two   \n",
       "1  __label__2 The best soundtrack ever to anythin...   two   \n",
       "2  __label__2 Amazing!: This soundtrack is my fav...   two   \n",
       "3  __label__2 Excellent Soundtrack: I truly like ...   two   \n",
       "4  __label__2 Remember, Pull Your Jaw Off The Flo...   two   \n",
       "5  __label__2 an absolute masterpiece: I am quite...   two   \n",
       "6  __label__1 Buyer beware: This is a self-publis...   one   \n",
       "7  __label__2 Glorious story: I loved Whisper of ...   two   \n",
       "8  __label__2 A FIVE STAR BOOK: I just finished r...   two   \n",
       "9  __label__2 Whispers of the Wicked Saints: This...   two   \n",
       "\n",
       "                                                text  \\\n",
       "0   Stuning even for the non-gamer: This sound tr...   \n",
       "1   The best soundtrack ever to anything.: I'm re...   \n",
       "2   Amazing!: This soundtrack is my favorite musi...   \n",
       "3   Excellent Soundtrack: I truly like this sound...   \n",
       "4   Remember, Pull Your Jaw Off The Floor After H...   \n",
       "5   an absolute masterpiece: I am quite sure any ...   \n",
       "6   Buyer beware: This is a self-published book, ...   \n",
       "7   Glorious story: I loved Whisper of the wicked...   \n",
       "8   A FIVE STAR BOOK: I just finished reading Whi...   \n",
       "9   Whispers of the Wicked Saints: This was a eas...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  stuning even nongamer sound track beautiful pa...  \n",
       "1  best soundtrack ever anything im reading lot r...  \n",
       "2  amazing soundtrack favorite music time hands i...  \n",
       "3  excellent soundtrack truly like soundtrack enj...  \n",
       "4  remember pull jaw floor hearing youve played g...  \n",
       "5  absolute masterpiece quite sure actually takin...  \n",
       "6  buyer beware selfpublished book want know whyr...  \n",
       "7  glorious story loved whisper wicked saints sto...  \n",
       "8  five star book finished reading whisper wicked...  \n",
       "9  whispers wicked saints easy read book made wan...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412692"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After text cleaning and removing stop words and some symbol words, we have only over 4 million words to work with!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Train — test split\n",
    "\n",
    "Spiliting data set into tran dataset and test dataset, there are some methods we choose:\n",
    "* 80% for training dataset and 20% for testing dataset\n",
    "* k-folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% for training dataset and 30% for testing dataset\n",
    "text = df.clean_text\n",
    "labels = df.label\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, labels, test_size=0.2, random_state = 66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Text Representation\n",
    "\n",
    "in order to represent our text, every row of the dataset will be a single document of the corpus. The columns (features) will be different depending of which feature creation method we choose:\n",
    "\n",
    "* Tokenzation\n",
    "* Count Vectors as features\n",
    "* TF-IDF Vectors as features\n",
    "    * Word level\n",
    "    * N-Gram level\n",
    "    * Character level\n",
    "* Word Embeddings as features(GloVe, FastText, and Word2Vec)\n",
    "\n",
    "And we could choose the sklean.pipeline to help us build text representation and modeling together "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectors as features\n",
    "Count Vector is a matrix notation of the dataset in which every row represents a document from the corpus, every column represents a term from the corpus, and every cell represents the frequency count of a particular term in a particular document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(df['text'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(X_train)\n",
    "xtest_count =  count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectors as features\n",
    "TF-IDF score represents the relative importance of a term in the document and the entire corpus. TF-IDF score is composed by two terms: the first computes the normalized Term Frequency (TF), the second term is the Inverse Document Frequency (IDF), computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears.\n",
    "\n",
    "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
    "IDF(t) = log_e(Total number of documents / Number of documents with term t in it)\n",
    "\n",
    "TF-IDF Vectors can be generated at different levels of input tokens (words, characters, n-grams)\n",
    "\n",
    "* Word Level TF-IDF : Matrix representing tf-idf scores of every term in different documents\n",
    "* N-gram Level TF-IDF : N-grams are the combination of N terms together. This Matrix representing tf-idf scores of N-grams\n",
    "* Character Level TF-IDF : Matrix representing tf-idf scores of character level n-grams in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', max_df=0.7)\n",
    "tfidf_vect.fit(df['text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(X_train)\n",
    "xtest_tfidf =  tfidf_vect.transform(X_test)\n",
    "\n",
    "# ngram level tf-idf \n",
    "# setting ngram_range(2,3) represents two word and three word markers\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', ngram_range=(2,3), max_df=0.7)\n",
    "tfidf_vect_ngram.fit(df['text'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(X_train)\n",
    "xtest_tfidf_ngram =  tfidf_vect_ngram.transform(X_test)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', ngram_range=(2,3), max_df=0.7)\n",
    "tfidf_vect_ngram_chars.fit(df['text'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(X_train) \n",
    "xtest_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tried the following models:\n",
    "\n",
    "* Conventional Machine Learning Algorithm\n",
    "    * Random Forest\n",
    "    * SVM\n",
    "    * NB(Naive Bayes)\n",
    "    * Logistic Regression\n",
    "    * Gradient Boosting\n",
    "* Deep learning Algorithm(Based on unqiue data transformation process and training process)\n",
    "    * BERT\n",
    "    * LSTM\n",
    "    * CNN\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I build a utility function which can be used to train a model. It accepts the classifier, feature_vector of training data, labels of training data and feature vectors of valid data as inputs. Using these inputs, the model is trained and accuracy score is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.826\n",
      "NB, WordLevel TF-IDF:  0.831\n",
      "NB, N-Gram Vectors:  0.7735\n",
      "NB, CharLevel Vectors:  0.797\n"
     ]
    }
   ],
   "source": [
    "import sklearn.naive_bayes as naive_bayes\n",
    "\n",
    "\n",
    "# Naive Bayes on Count Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, y_train, xtest_count)\n",
    "print (\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print (\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, y_train, xtest_tfidf_ngram)\n",
    "print (\"NB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, y_train, xtest_tfidf_ngram_chars)\n",
    "print (\"NB, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Count Vectors:  0.846\n",
      "LR, WordLevel TF-IDF:  0.845\n",
      "LR, N-Gram Vectors:  0.775\n",
      "LR, CharLevel Vectors:  0.8235\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model as linear_model\n",
    "\n",
    "# Linear Classifier on Count Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, y_train, xtest_count)\n",
    "print (\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print (\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, y_train, xtest_tfidf_ngram)\n",
    "print (\"LR, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, y_train, xtest_tfidf_ngram_chars)\n",
    "print (\"LR, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "The model extracts a best possible hyper-plane / line that segregates the two classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, Count Vectors:  0.8365\n",
      "SVM, WordLevel TF-IDF:  0.8485\n",
      "SVM, N-Gram Vectors:  0.7785\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# SVM on Count Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_count, y_train, xtest_count)\n",
    "print (\"SVM, Count Vectors: \", accuracy)\n",
    "\n",
    "# SVM on Word Level TF IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print (\"SVM, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, y_train, xtest_tfidf_ngram)\n",
    "print (\"SVM, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model\n",
    "Random Forest models are a type of ensemble models, particularly bagging models. They are part of the tree based model family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Count Vectors:  0.826\n",
      "RF, WordLevel TF-IDF:  0.8255\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "# RF on Count Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_count, y_train, xtest_count)\n",
    "print (\"RF, Count Vectors: \", accuracy)\n",
    "\n",
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print (\"RF, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, Count Vectors:  0.824\n",
      "Xgb, WordLevel TF-IDF:  0.8105\n",
      "Xgb, CharLevel Vectors:  0.792\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Gradient Boosting on Count Vectors\n",
    "accuracy = train_model(XGBClassifier(), xtrain_count, y_train, xtest_count.tocsc())\n",
    "print (\"Xgb, Count Vectors: \", accuracy)\n",
    "\n",
    "# Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy = train_model(XGBClassifier(), xtrain_tfidf, y_train, xtest_tfidf.tocsc())\n",
    "print (\"Xgb, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Gradient Boosting on Character Level TF IDF Vectors\n",
    "accuracy = train_model(XGBClassifier(), xtrain_tfidf_ngram_chars, y_train, xtest_tfidf_ngram_chars.tocsc())\n",
    "print (\"Xgb, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve a higher accuracy score of 84.6% which is 0.1% improvement over Naive Bayes and 0.05% improvement over Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Performance Measurement\n",
    "\n",
    "When dealing with classification problems, there are several metrics that can be used to gain insights on how the model is performing. Some of them are:\n",
    " \n",
    " * Accuracy\n",
    " * confusion matrix\n",
    " * Precision\n",
    " * Recall\n",
    " * F1-Score\n",
    " * ROC\n",
    " * classification report(for the SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "Continue with our best model (LinearSVC), we are going to look at the confusion matrix, and show the discrepancies between predicted and actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = svm.SVC()\n",
    "model.fit(xtrain_tfidf, y_train)\n",
    "y_pred = model.predict(xtest_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[880, 145],\n",
       "       [158, 817]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y_test, y_pred, labels=['one', 'two'])\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         two       0.85      0.86      0.85      1025\n",
      "         one       0.85      0.84      0.84       975\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.85      0.85      0.85      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=df['label'].unique()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
